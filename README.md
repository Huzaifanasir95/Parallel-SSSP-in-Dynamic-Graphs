Parallel SSSP Implementation for Dynamic Networks
This project implements a parallel algorithm for updating Single-Source Shortest Paths (SSSP) in large-scale dynamic networks, based on the research paper: A Parallel Algorithm Template for Updating Single-Source Shortest Paths in Large-Scale Dynamic Networks. The implementation uses MPI for inter-node communication, OpenMP for intra-node parallelism, and METIS for graph partitioning. The code is designed to handle dynamic graph updates (edge insertions and deletions) efficiently and evaluate scalability across multiple machines.
Project Overview
The program, dynamic_sssp_mpi.c, performs the following tasks:

Loads a graph from an edge list file.
Partitions the graph using METIS to distribute vertices across MPI ranks.
Computes an initial SSSP tree using Dijkstra's algorithm.
Processes a specified number of random edge edits (insertions and deletions) in batches.
Updates the SSSP tree using a four-phase approach: deletion processing, insertion processing, deletion propagation, and relaxation with ghost vertex exchange.
Outputs timing metrics for each phase, communication, CPU, and wall clock time.
Logs the final SSSP tree and computes accuracy against a sequential Dijkstra's run.

Prerequisites

MPI: Install an MPI implementation (e.g., OpenMPI or MPICH).
METIS: Install the METIS library for graph partitioning.
OpenMP: Ensure a compiler with OpenMP support (e.g., GCC).
SSH: Configure passwordless SSH for communication between machines.
C Compiler: GCC or compatible compiler with C99 support.
Operating System: Linux (tested on Ubuntu).

Cluster Setup
The implementation was tested on a cluster of two PCs communicating via MPI. Below are the steps to set up the cluster:

Create MPI User:

On both PCs, create a user mpiuser1:sudo adduser mpiuser1


Switch to mpiuser1:su - mpiuser1




Install Dependencies:

Install MPI, METIS, and SSH:sudo apt update
sudo apt install openmpi-bin openmpi-common libopenmpi-dev metis libmetis-dev openssh-server openssh-client build-essential




Configure SSH:

Generate SSH keys for mpiuser1 on both PCs:ssh-keygen -t rsa


Copy the public key to the other PC:ssh-copy-id mpiuser1@<other_pc_ip>


Test passwordless SSH:ssh mpiuser1@<other_pc_ip>




Configure Hosts File:

Edit /etc/hosts on both PCs to include IP addresses and hostnames:sudo nano /etc/hosts

Add:<pc1_ip> pc1
<pc2_ip> pc2




Create MPI Hostfile:

In the home directory of mpiuser1 on the master PC (pc1), create a file hosts:nano hosts

Add:pc1 slots=2
pc2 slots=2





Compilation and Execution

Compile the Code:

Compile dynamic_sssp_mpi.c with METIS and OpenMP support:mpicc -g -O3 -std=c99 -fopenmp dynamic_sssp_mpi.c -lmetis -lm -o dsssp




Copy Executable to Other PC:

Copy the compiled binary to pc2:scp ~/mpi_programs/dsssp mpiuser1@pc2:~/mpi_programs/




Run the Program:

Execute the program with 4 processes (2 per PC) using the hostfile:mpirun --verbose -np 4 --hostfile hosts ./dsssp data.txt 500 50


Arguments:
data.txt: Input file containing the edge list (format: u v w per line, where u and v are vertices and w is the edge weight).
500: Number of total edge edits (insertions + deletions).
50: Percentage of edits that are insertions (50% means 250 insertions and 250 deletions).





Input File Format
The input file (data.txt) should contain one edge per line in the format:
u v w


u, v: Vertex IDs (0-based integers).
w: Edge weight (positive integer).

Example:
0 1 5
1 2 3
2 0 7

Output

Console Output:

Number of vertices and edges loaded.
Phase timings (deletion, insertion, propagation, relax+ghost).
Total communication, CPU, and wall clock time per rank.
Cumulative CPU time across all ranks.


Log File (log.txt):

Generated by rank 0, containing the final SSSP tree:Final SSSP Tree:
Vertex  Distance    Parent
0       0           -1
1       5           0
2       8           1
...





Scalability and Performance

Scalability: The program evaluates weak and strong scaling by distributing the graph across multiple MPI ranks and processing edits in parallel.
METIS Partitioning: Ensures balanced vertex distribution and minimizes inter-node communication.
OpenMP: Parallelizes computation within each node for deletion, insertion, and relaxation phases.
Batching: Edits are processed in batches (default size: 30) to improve load balancing.

Notes

Ensure the input graph has positive edge weights, as negative weights are not supported.
The program assumes the input graph is undirected; each edge is added bidirectionally.
Accuracy is computed by comparing the parallel SSSP tree against a sequential Dijkstra's run on the updated graph.
The GitHub repository should include incremental commits to reflect project progress, as per the project requirements.

References

Research Paper: A Parallel Algorithm Template for Updating Single-Source Shortest Paths in Large-Scale Dynamic Networks https://drive.google.com/file/d/1Cj7u6bLfbwfjSwtZhfDwv4V5wIuiGB9y/view?usp=sharing
METIS Documentation: https://github.com/KarypisLab/METIS

